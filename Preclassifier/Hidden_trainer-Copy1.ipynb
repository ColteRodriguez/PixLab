{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31ebd973-2155-455d-9513-450f1232a14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Normalized image size\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(root='/Users/coltenrodriguez/Desktop/dataset2/train', transform=transform)\n",
    "val_dataset = ImageFolder(root='/Users/coltenrodriguez/Desktop/dataset2/val', transform=transform)\n",
    "\n",
    "# data --> Pytorch Objects\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d54bdd91-34de-4d10-ae74-b1f8f6d2aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Initialize a resnet model\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)  # Assuming 2 classes: Constituent and Background\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6a43be1-3ee7-4b3e-99d9-0d92559565a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/25 - Loss: 0.4361\n",
      "Epoch 1/25 - Loss: 0.1334\n",
      "Epoch 2/25 - Loss: 0.0446\n",
      "Epoch 3/25 - Loss: 0.0462\n",
      "Epoch 4/25 - Loss: 0.1779\n",
      "Epoch 5/25 - Loss: 0.0530\n",
      "Epoch 6/25 - Loss: 0.0731\n",
      "Epoch 7/25 - Loss: 0.0407\n",
      "Epoch 8/25 - Loss: 0.0352\n",
      "Epoch 9/25 - Loss: 0.0132\n",
      "Epoch 10/25 - Loss: 0.0235\n",
      "Epoch 11/25 - Loss: 0.0234\n",
      "Epoch 12/25 - Loss: 0.0098\n",
      "Epoch 13/25 - Loss: 0.0024\n",
      "Epoch 14/25 - Loss: 0.0103\n",
      "Epoch 15/25 - Loss: 0.0076\n",
      "Epoch 16/25 - Loss: 0.0021\n",
      "Epoch 17/25 - Loss: 0.0007\n",
      "Epoch 18/25 - Loss: 0.0002\n",
      "Epoch 19/25 - Loss: 0.0001\n",
      "Epoch 20/25 - Loss: 0.0014\n",
      "Epoch 21/25 - Loss: 0.0004\n",
      "Epoch 22/25 - Loss: 0.0002\n",
      "Epoch 23/25 - Loss: 0.0005\n",
      "Epoch 24/25 - Loss: 0.0002\n"
     ]
    }
   ],
   "source": [
    "# Train the resnet model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "num_epochs = 25\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print(f'Epoch {epoch}/{num_epochs} - Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6898048-d71b-49a3-90db-4e1bf3a76574",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'Preclassifier_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a271a4ac-0d90-4692-a384-d9b4c5d88b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Background', 'Constituent']\n",
      "Constituent\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image \n",
    "\n",
    "# Test the trained model. Can use files from /val for this\n",
    "model.load_state_dict(torch.load('Preclassifier_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "def classify_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    image = image.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        class_names = train_dataset.classes\n",
    "        print(class_names)\n",
    "        return class_names[preds.item()]\n",
    "\n",
    "print(classify_image('/Users/coltenrodriguez/Downloads/Img0026.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f54e2a-3129-4c21-9bd4-60ce1f1e62c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
